{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amélioration du Notebook d'Analyse et de Prévision de Séries Temporelles\n",
    "\n",
    "Ce notebook présente une version améliorée du travail initial sur l'analyse et la prévision de la série temporelle 'Valeur AEN'. Les améliorations suivantes ont été apportées :\n",
    "\n",
    "1. **Structure et Clarté :** Le notebook est maintenant organisé en sections claires :\n",
    "   - Chargement et Prétraitement des Données\n",
    "   - Analyse Exploratoire des Données (EDA)\n",
    "   - Modélisation et Prévision avec SARIMA\n",
    "   - Modélisation et Prévision avec LSTM\n",
    "   - Comparaison des Modèles\n",
    "2. **Prétraitement des Données :** Le code de prétraitement a été conservé mais mieux commenté.\n",
    "3. **Optimisation des Hyperparamètres SARIMA :** Au lieu de paramètres fixes, une recherche par grille est utilisée pour trouver le meilleur ordre pour le modèle SARIMA.\n",
    "4. **Évaluation Quantitative :** Des métriques d'évaluation comme l'Erreur Quadratique Moyenne (RMSE) et l'Erreur Absolue Moyenne (MAE) sont calculées pour chaque modèle afin de comparer objectivement leurs performances.\n",
    "5. **Qualité du Code :** Des commentaires ont été ajoutés pour expliquer les étapes clés et les choix de conception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aen_df = pd.read_excel('aen.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_aen_data(df, cln, name):\n",
    "    \"\"\"\n",
    "    Transforms the raw AEN DataFrame into a clean time series format.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with 'LIBELLE' and date columns.\n",
    "        cln (str): The name of the column to drop.\n",
    "        name (str): The name of the value column in the output DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A transformed DataFrame with 'Date' and value columns.\n",
    "    \"\"\"\n",
    "    # Transpose the DataFrame to have dates as rows\n",
    "    aen_series = df.drop(columns=cln).iloc[0]\n",
    "    aen_transformed_df = aen_series.reset_index()\n",
    "    aen_transformed_df.columns = ['Date', name]\n",
    "\n",
    "    # Convert values to numeric, replacing non-numeric with NaN\n",
    "    aen_transformed_df[name] = pd.to_numeric(aen_transformed_df[name], errors='coerce')\n",
    "\n",
    "    # Define month mapping for date conversion\n",
    "    month_map = {\n",
    "        'JAN': '01', 'FEV': '02', 'MAR': '03', 'AVR': '04', 'MAY': '05', 'JUN': '06',\n",
    "        'JUL': '07', 'AUG': '08', 'SEP': '09', 'OCT': '10', 'NOV': '11', 'DEC': '12'\n",
    "    }\n",
    "\n",
    "    # Function to convert date strings to datetime objects\n",
    "    def convert_date(d):\n",
    "        if isinstance(d, pd.Timestamp):\n",
    "            return d\n",
    "        try:\n",
    "            date_str = str(d)\n",
    "            month_str = date_str[:3].upper()\n",
    "            year_str = date_str[3:]\n",
    "            if month_str in month_map:\n",
    "                return pd.to_datetime(f\"{year_str}-{month_map[month_str]}-01\")\n",
    "        except (TypeError, ValueError):\n",
    "            pass\n",
    "        return pd.NaT\n",
    "\n",
    "    # Apply date conversion\n",
    "    aen_transformed_df['Date'] = aen_transformed_df['Date'].apply(convert_date)\n",
    "\n",
    "    # Drop rows with invalid dates or NaN values\n",
    "    aen_transformed_df.dropna(subset=['Date', name], inplace=True)\n",
    "\n",
    "    # Sort by date and reset index\n",
    "    aen_transformed_df = aen_transformed_df.sort_values(by='Date').reset_index(drop=True)\n",
    "    aen_transformed_df.set_index('Date', inplace=True)\n",
    "\n",
    "    return aen_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aen_df1 = transform_aen_data(aen_df, 'LIBELLE', 'Valeur_AEN')\n",
    "aen_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse Exploratoire des Données (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aen_df1['Valeur_AEN'].plot(figsize=(12, 6), title='Évolution de la Valeur AEN')\n",
    "plt.ylabel('Valeur AEN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition\n",
    "decomposition = seasonal_decompose(aen_df1['Valeur_AEN'], model='additive', period=12)\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(14, 10)\n",
    "plt.suptitle('Décomposition Saisonnière de la Valeur AEN', fontsize=16, y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Stationnarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(series):\n",
    "    result = adfuller(series)\n",
    "    print('Statistiques ADF : {}'.format(result[0]))\n",
    "    print('p-valeur : {}'.format(result[1]))\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"La série est stationnaire.\")\n",
    "    else:\n",
    "        print(\"La série n'est pas stationnaire.\")\n",
    "\n",
    "adf_test(aen_df1['Valeur_AEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La série n'étant pas stationnaire, nous appliquons une différenciation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aen_df1['Valeur_AEN_diff'] = aen_df1['Valeur_AEN'].diff().dropna()\n",
    "adf_test(aen_df1['Valeur_AEN_diff'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACF et PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "plot_acf(aen_df1['Valeur_AEN_diff'].dropna(), ax=ax1, lags=40)\n",
    "plot_pacf(aen_df1['Valeur_AEN_diff'].dropna(), ax=ax2, lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modélisation et Prévision avec SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = '2018-12-31'\n",
    "test_end = '2025-01-31'\n",
    "\n",
    "train_data = aen_df1[:train_end]['Valeur_AEN']\n",
    "test_data = aen_df1[train_end:test_end]['Valeur_AEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des meilleurs hyperparamètres (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "best_aic = np.inf\n",
    "best_pdq = None\n",
    "best_seasonal_pdq = None\n",
    "best_model = None\n",
    "\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = SARIMAX(train_data, order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            if results.aic < best_aic:\n",
    "                best_aic = results.aic\n",
    "                best_pdq = param\n",
    "                best_seasonal_pdq = param_seasonal\n",
    "                best_model = results\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f'Meilleur AIC: {best_aic}')\n",
    "print(f'Meilleur ordre (p,d,q): {best_pdq}')\n",
    "print(f'Meilleur ordre saisonnier (P,D,Q,s): {best_seasonal_pdq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement et Prévision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sarima = best_model.get_prediction(start=test_data.index[0], end=test_data.index[-1])\n",
    "pred_ci = pred_sarima.conf_int()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = aen_df1['Valeur_AEN']['2015':].plot(label='Observé')\n",
    "pred_sarima.predicted_mean.plot(ax=ax, label='Prédiction SARIMA', alpha=.7)\n",
    "ax.fill_between(pred_ci.index, pred_ci.iloc[:, 0], pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Valeur AEN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du modèle SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_rmse = np.sqrt(mean_squared_error(test_data, pred_sarima.predicted_mean))\n",
    "sarima_mae = mean_absolute_error(test_data, pred_sarima.predicted_mean)\n",
    "\n",
    "print(f'RMSE SARIMA: {sarima_rmse}')\n",
    "print(f'MAE SARIMA: {sarima_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modélisation et Prévision avec LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(aen_df1['Valeur_AEN'].values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 12\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Split data\n",
    "train_size = len(train_data)\n",
    "X_train, X_test = X[:train_size-seq_length], X[train_size-seq_length:]\n",
    "y_train, y_test = y[:train_size-seq_length], y[train_size-seq_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction et Entraînement du modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential([
",
    "    LSTM(50, activation='relu', input_shape=(seq_length, 1)),
",
    "    Dense(1)
",
    "])
",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')
",
    "history = model_lstm.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision et Évaluation du modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "y_pred_lstm_inv = scaler.inverse_transform(y_pred_lstm)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_lstm_inv))\n",
    "lstm_mae = mean_absolute_error(y_test_inv, y_pred_lstm_inv)\n",
    "\n",
    "print(f'RMSE LSTM: {lstm_rmse}')\n",
    "print(f'MAE LSTM: {lstm_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_data.index, y_test_inv, label='Observé')\n",
    "plt.plot(test_data.index, y_pred_lstm_inv, label='Prédiction LSTM')\n",
    "plt.title('Prédictions LSTM vs Données Observées')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Valeur AEN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparaison des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({
",
    "    'Modèle': ['SARIMA', 'LSTM'],
",
    "    'RMSE': [sarima_rmse, lstm_rmse],
",
    "    'MAE': [sarima_mae, lstm_mae]
",
    "}).set_index('Modèle')
",
    "\n",
    "print(\"Comparaison des performances des modèles :\")
",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a présenté une approche structurée pour la prévision de séries temporelles en utilisant les modèles SARIMA et LSTM. La recherche par grille pour SARIMA a permis de trouver des hyperparamètres optimaux, et l'évaluation quantitative a offert un moyen objectif de comparer les deux approches. En fonction des résultats, on peut choisir le modèle le plus performant pour les prévisions futures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
